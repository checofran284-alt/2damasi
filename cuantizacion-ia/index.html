<!DOCTYPE html><html lang="es"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><title>&quot; CUANTIZACI√ìN IA &quot; - ASI</title><meta name="description" content="Integrantes: Francisco Ferres , Pablo P√©rez, Mario P√©rez ____________________________________________________________________________________________________________ INDICE: ____________________________________________________________________________________________________________ Para la semana del 12 de Febrero de 2026¬†se&hellip;"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://checofran284-alt.github.io/2damasi/cuantizacion-ia/"><link rel="alternate" type="application/atom+xml" href="https://checofran284-alt.github.io/2damasi/feed.xml" title="ASI - RSS"><link rel="alternate" type="application/json" href="https://checofran284-alt.github.io/2damasi/feed.json" title="ASI - JSON"><meta property="og:title" content="' CUANTIZACI√ìN IA '"><meta property="og:image" content="https://checofran284-alt.github.io/2damasi/media/website/logo-para-web-person.png"><meta property="og:image:width" content="1536"><meta property="og:image:height" content="1024"><meta property="og:site_name" content="ASI"><meta property="og:description" content="Integrantes: Francisco Ferres , Pablo P√©rez, Mario P√©rez ____________________________________________________________________________________________________________ INDICE: ____________________________________________________________________________________________________________ Para la semana del 12 de Febrero de 2026¬†se&hellip;"><meta property="og:url" content="https://checofran284-alt.github.io/2damasi/cuantizacion-ia/"><meta property="og:type" content="article"><link rel="shortcut icon" href="https://checofran284-alt.github.io/2damasi/media/website/logo-para-web-person-2.png" type="image/x-icon"><link rel="stylesheet" href="https://checofran284-alt.github.io/2damasi/assets/css/fontawesome-all.min.css?v=85514f933f9e0b82460af63f1a403fa5"><link rel="stylesheet" href="https://checofran284-alt.github.io/2damasi/assets/css/style.css?v=a223b81ec98329445fe871c45c7278db"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://checofran284-alt.github.io/2damasi/cuantizacion-ia/"},"headline":"\" CUANTIZACI√ìN IA \"","datePublished":"2026-02-17T20:49+01:00","dateModified":"2026-02-18T15:29+01:00","image":{"@type":"ImageObject","url":"https://checofran284-alt.github.io/2damasi/media/website/logo-para-web-person.png","height":1024,"width":1536},"description":"Integrantes: Francisco Ferres , Pablo P√©rez, Mario P√©rez ____________________________________________________________________________________________________________ INDICE: ____________________________________________________________________________________________________________ Para la semana del 12 de Febrero de 2026¬†se&hellip;","author":{"@type":"Person","name":"Francisco Ferres Brice√±o","url":"https://checofran284-alt.github.io/2damasi/authors/francisco-ferres/"},"publisher":{"@type":"Organization","name":"Francisco Ferres Brice√±o","logo":{"@type":"ImageObject","url":"https://checofran284-alt.github.io/2damasi/media/website/logo-para-web-person.png","height":1024,"width":1536}}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript></head><body class="is-preload post-template"><div id="wrapper"><div id="main"><div class="inner"><header id="header"><a class="logo logo-image" href="https://checofran284-alt.github.io/2damasi/"><img src="https://checofran284-alt.github.io/2damasi/media/website/logo-para-web-person.png" alt="ASI" width="1536" height="1024"></a></header><article class="post"><header class="main post__header"><time datetime="2026-02-17T20:49" class="post__date">febrero 17, 2026</time><h1>&quot; CUANTIZACI√ìN IA &quot;</h1></header><div class="post__inner post__entry"><figure class="post__image post__image--wide"><img loading="lazy" src="https://checofran284-alt.github.io/2damasi/media/posts/29/Ilustracion.png" alt="" width="1024" height="1338" sizes="(max-width: 48em) 100vw, 768px" srcset="https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Ilustracion-xs.png 300w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Ilustracion-sm.png 480w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Ilustracion-md.png 768w"></figure><p class="align-center"><strong><span style="text-decoration: underline;">Integrantes: Francisco Ferres , Pablo P√©rez, Mario P√©rez</span></strong></p><p>____________________________________________________________________________________________________________</p><p class="align-left">INDICE:</p><ol class="align-center"><li class="align-left">Introducci√≥n</li><li class="align-left">Proceso de Destilar con IA</li><li class="align-left">Conclusi√≥n</li></ol><p class="align-left">____________________________________________________________________________________________________________</p><h5 class="align-left">1. INTRODUCCI√ìN</h5><p data-start="220" data-end="726"></p><p>Para la semana del<strong> 12 de Febrero de 2026</strong><span data-path-to-node="1,1"><span class="citation-354">¬†se llev√≥ a cabo la pr√°ctica de laboratorio centrada en la </span><strong data-path-to-node="1,1" data-index-in-node="99"><span class="citation-354">optimizaci√≥n y cuantizaci√≥n de Grandes Modelos de Lenguaje (LLMs)</span></strong><span class="citation-354"> en un entorno local</span></span><span data-path-to-node="1,3">.</span></p><p id="p-rc_6238f33949c0f844-172" data-path-to-node="1"></p><p data-path-to-node="2"></p><p>El prop√≥sito central de la sesi√≥n fue explorar c√≥mo reducir los requisitos de hardware necesarios para ejecutar inteligencia artificial generativa sin depender de equipos de alto rendimiento.</p><p>Para ello, se emple√≥ el framework <strong>llama.cpp</strong> sobre un sistema Windows, comenzando por la preparaci√≥n del entorno mediante la clonaci√≥n del repositorio oficial y la descarga de binarios compatibles con <strong>aceleraci√≥n gr√°fica mediante Vulkan</strong>. Una vez configurado el entorno, se procedi√≥ a la conversi√≥n del modelo <strong>Phi‚Äë3 Mini</strong>, transform√°ndolo desde su formato original en precisi√≥n <strong>F16</strong> a una versi√≥n cuantizada de <strong>4 bits (Q4_K_M)</strong>. Este proceso se llev√≥ a cabo utilizando las herramientas de cuantizaci√≥n incluidas en llama.cpp.</p><p>Finalmente, se verific√≥ el correcto funcionamiento del modelo cuantizado y se realiz√≥ una comparaci√≥n del ahorro de almacenamiento utilizando <strong>LM Studio</strong>, confirmando que la reducci√≥n de precisi√≥n no imped√≠a su carga ni su uso. En conjunto, la pr√°ctica permiti√≥ demostrar de forma pr√°ctica c√≥mo la cuantizaci√≥n puede hacer que modelos avanzados sean m√°s accesibles y eficientes en equipos locales.</p><p></p><p class="align-left">____________________________________________________________________________________________________________</p><h5 class="align-left">2. CONFIGURACI√ìN DEL AGENTE CON IA EN LOCAL</h5><p>El objetivo de esta pr√°ctica es reducir el tama√±o y consumo de memoria de un modelo de lenguaje (Phi-3 Mini) mediante t√©cnicas de cuantizaci√≥n. Se utiliza la herramienta <code data-path-to-node="3" data-index-in-node="170">llama.cpp</code> para convertir un modelo de precisi√≥n media (F16) a una cuantizaci√≥n de 4 bits (Q4_K_M), y finalmente se comparan los resultados de rendimiento y almacenamiento en LM Studio.</p><p class="align-center">A continuaci√≥n mostraremos los pasos a seguir...‚¨áÔ∏è</p><figure class="post__image post__image--full"><img loading="lazy" src="https://checofran284-alt.github.io/2damasi/media/posts/29/Captura-de-pantalla-2026-02-18-150357.png" alt="" width="604" height="344" sizes="(max-width: 48em) 100vw, 768px" srcset="https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150357-xs.png 300w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150357-sm.png 480w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150357-md.png 768w"></figure><p class="align-center">PASO 1 -¬† A CONTINUACI√ìN EXPLICARE EL PROCESO LLEVADO A CABO:</p><blockquote><p><span data-path-to-node="4,0">Lo primero que hicimos fue organizar nuestro espacio de trabajo para evitar errores de ubicaci√≥n de archivos. </span><span data-path-to-node="4,2"><span class="citation-222">En la terminal de Windows (PowerShell), creamos una carpeta espec√≠fica llamada </span><code data-path-to-node="4,2" data-index-in-node="79"><span class="citation-222">ejercicio-cuantizacion</span></code></span><span data-path-to-node="4,4">. </span><span data-path-to-node="4,6"><span class="citation-221">Una vez dentro de este directorio, clonamos el repositorio oficial de </span><strong><span class="citation-221">llama.cpp</span></strong><span class="citation-221"> utilizando el comando </span><code data-path-to-node="4,6" data-index-in-node="102"><span class="citation-221">git clone</span></code></span><span data-path-to-node="4,8">. Esto es fundamental para tener la estructura de carpetas y los scripts necesarios que el proyecto requiere para funcionar correctamente</span></p></blockquote><figure class="post__image post__image--full"><img loading="lazy" src="https://checofran284-alt.github.io/2damasi/media/posts/29/Captura-de-pantalla-2026-02-18-150402.png" alt="" width="607" height="337" sizes="(max-width: 48em) 100vw, 768px" srcset="https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150402-xs.png 300w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150402-sm.png 480w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150402-md.png 768w"></figure><p class="align-center">PASO 2 - A CONTINUACI√ìN EXPLICARE EL PROCESO LLEVADO A CABO:</p><blockquote><p data-path-to-node="6"><span data-path-to-node="6,0">Para poder ejecutar la cuantizaci√≥n en Windows sin necesidad de compilar c√≥digo complejo, descargamos los archivos ejecutables ya preparados. </span><span data-path-to-node="6,2"><span class="citation-220">Fuimos a la secci√≥n de "releases" (lanzamientos) del repositorio y descargamos el archivo comprimido </span><code data-path-to-node="6,2" data-index-in-node="101"><span class="citation-220">llama-b6680-bin-win-vulkan-x64.zip</span></code></span><span data-path-to-node="6,4">. </span><span data-path-to-node="6,6"><span class="citation-219">Elegimos la versi√≥n con soporte </span><strong data-path-to-node="6,6" data-index-in-node="32"><span class="citation-219">Vulkan</span></strong> </span><span data-path-to-node="6,8">para asegurar que el proceso pudiera aprovechar la aceleraci√≥n gr√°fica si fuera necesario.</span></p><p id="p-rc_5861e7e87eaa9e38-127" data-path-to-node="6"></p><p id="p-rc_5861e7e87eaa9e38-128" data-path-to-node="7"><span data-path-to-node="7,1"><span class="citation-218">Un punto crucial de este paso fue descomprimir el contenido de este archivo ZIP (que incluye </span><code data-path-to-node="7,1" data-index-in-node="93"><span class="citation-218">llama-quantize.exe</span></code><span class="citation-218">) exactamente en la misma carpeta donde ten√≠amos guardado nuestro modelo original (</span><code data-path-to-node="7,1" data-index-in-node="194"><span class="citation-218">phi-3-mini-f16.gguf</span></code><span class="citation-218">)</span></span><span data-path-to-node="7,3">. Esto simplifica mucho el proceso, ya que evita tener que escribir rutas de acceso largas y complicadas en la terminal</span></p></blockquote><figure class="post__image post__image--full"><img loading="lazy" src="https://checofran284-alt.github.io/2damasi/media/posts/29/Captura-de-pantalla-2026-02-18-150407.png" alt="" width="605" height="341" sizes="(max-width: 48em) 100vw, 768px" srcset="https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150407-xs.png 300w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150407-sm.png 480w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150407-md.png 768w"></figure><p class="align-center">PASO 3 - A CONTINUACI√ìN EXPLICARE EL PROCESO LLEVADO A CABO:</p><blockquote><p data-path-to-node="9"><span data-path-to-node="9,0">Con las herramientas y el modelo en la misma ubicaci√≥n, procedimos a la conversi√≥n. </span><span data-path-to-node="9,2"><span class="citation-217">En la terminal de PowerShell, ejecutamos el comando de cuantizaci√≥n</span></span><span data-path-to-node="9,4">.</span></p><div class="source-inline-chip-container ng-star-inserted">¬†</div><p id="p-rc_5861e7e87eaa9e38-129" data-path-to-node="9"></p><p data-path-to-node="10">Le indicamos al programa <code data-path-to-node="10" data-index-in-node="25">llama-quantize.exe</code> tres cosas:</p><ol start="1" data-path-to-node="11"><li><p data-path-to-node="11,0,0"><strong data-path-to-node="11,0,0" data-index-in-node="0">El origen:</strong> El modelo pesado en alta calidad (<code data-path-to-node="11,0,0" data-index-in-node="45">phi-3-mini-f16.gguf</code>).</p></li><li><p data-path-to-node="11,1,0"><strong data-path-to-node="11,1,0" data-index-in-node="0">El destino:</strong> El nombre que quer√≠amos para el nuevo archivo (<code data-path-to-node="11,1,0" data-index-in-node="59">phi-3-mini-Q4_K_M.gguf</code>).</p></li><li><p data-path-to-node="11,2,0"><strong data-path-to-node="11,2,0" data-index-in-node="0">El m√©todo:</strong> El tipo de compresi√≥n <code data-path-to-node="11,2,0" data-index-in-node="33">Q4_K_M</code>, que reduce la precisi√≥n de los datos a 4 bits.</p></li></ol></blockquote><figure class="post__image post__image--full"><img loading="lazy" src="https://checofran284-alt.github.io/2damasi/media/posts/29/Captura-de-pantalla-2026-02-18-150413.png" alt="" width="604" height="341" sizes="(max-width: 48em) 100vw, 768px" srcset="https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150413-xs.png 300w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150413-sm.png 480w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150413-md.png 768w"></figure><p class="align-center">PASO 4 - AQU√ç PODEMOS OBSERVAR QUE SE GUARDO CORRECTAMENTE, LO QUE NOS LLEVAR√Å AL ULTIMO PASO...</p><figure class="post__image post__image--full"><img loading="lazy" src="https://checofran284-alt.github.io/2damasi/media/posts/29/Captura-de-pantalla-2026-02-18-150419.png" alt="" width="608" height="343" sizes="(max-width: 48em) 100vw, 768px" srcset="https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150419-xs.png 300w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150419-sm.png 480w, https://checofran284-alt.github.io/2damasi/media/posts/29/responsive/Captura-de-pantalla-2026-02-18-150419-md.png 768w"></figure><p class="align-center">PASO FINAL -¬† A CONTINUACI√ìN EXPLICARE EL PROCESO LLEVADO A CABO:</p><blockquote><p data-path-to-node="13">Finalmente, para comprobar que el proceso fue exitoso y √∫til, cargamos ambos modelos en la aplicaci√≥n <strong data-path-to-node="13" data-index-in-node="102">LM Studio</strong> para compararlos. La diferencia fue notable:</p><ul><li data-path-to-node="14,0,0"><span data-path-to-node="14,0,0,1"><span class="citation-216">El modelo original (F16) ocupaba </span><strong data-path-to-node="14,0,0,1" data-index-in-node="33"><span class="citation-216">7.12 GB</span></strong><span class="citation-216"> en el disco.</span></span></li><li data-path-to-node="14,0,0"><span data-path-to-node="14,1,0,1"><span class="citation-215">El nuevo modelo cuantizado (Q4) que generamos ocup√≥ solo </span><strong data-path-to-node="14,1,0,1" data-index-in-node="57"><span class="citation-215">2.23 GB</span></strong></span><span data-path-to-node="14,1,0,3">.</span></li></ul><p id="p-rc_5861e7e87eaa9e38-130" data-path-to-node="14,0,0"></p><p id="p-rc_5861e7e87eaa9e38-131" data-path-to-node="14,1,0"></p><p data-path-to-node="15">Esto demuestra que logramos reducir el peso del modelo a menos de un tercio de su tama√±o original, haci√©ndolo mucho m√°s ligero y r√°pido de ejecutar en ordenadores personales</p></blockquote><p class="align-left">____________________________________________________________________________________________________________</p><h5 class="align-left">3. CONCLUSI√ìN</h5><p>Esta pr√°ctica ha demostrado con √©xito la eficacia de las t√©cnicas de cuantizaci√≥n para optimizar <strong>Grandes Modelos de Lenguaje (LLMs</strong>), permitiendo su ejecuci√≥n en equipos con recursos limitados. En lugar de centrarnos √∫nicamente en el rendimiento bruto del modelo, la actividad puso el foco en la optimizaci√≥n estructural, mostrando c√≥mo la reducci√≥n de precisi√≥n puede convertirse en una herramienta clave para la ejecuci√≥n local de IA avanzada.</p><p>El uso combinado de llama.cpp y la aceleraci√≥n mediante <strong>Vulkan </strong>facilit√≥ la conversi√≥n del modelo <strong>Phi‚Äë3 Mini</strong> a un formato mucho m√°s compacto. El proceso t√©cnico realizado con <strong>llama‚Äëquantize.exe</strong> permiti√≥ aplicar el esquema de cuantizaci√≥n <strong>Q4_K_M</strong>, una t√©cnica que reduce el tama√±o del modelo manteniendo una representaci√≥n eficiente de sus pesos. La operaci√≥n se ejecut√≥ sin incidencias, lo que confirm√≥ la estabilidad del flujo de trabajo y la compatibilidad del modelo con este tipo de compresi√≥n.</p><p>Uno de los resultados m√°s relevantes fue la reducci√≥n dr√°stica del tama√±o del modelo. El archivo original en formato <strong>F16 ocupaba 7.12 GB</strong>, mientras que la versi√≥n cuantizada descendi√≥ hasta <strong>2.23 GB</strong>, lo que supone un ahorro cercano al 70%. Esta disminuci√≥n no solo libera espacio en disco, sino que tambi√©n reduce la carga sobre la memoria VRAM, permitiendo que dispositivos m√°s modestos puedan ejecutar modelos que, en condiciones normales, quedar√≠an fuera de su alcance.</p><p>Finalmente, la validaci√≥n en LM Studio confirm√≥ que el modelo cuantizado segu√≠a siendo plenamente funcional. A pesar de la reducci√≥n de precisi√≥n, el sistema fue capaz de reconocerlo, cargarlo y utilizarlo sin problemas. Esto demuestra que la cuantizaci√≥n no solo es una t√©cnica de compresi√≥n, sino una estrategia realista para democratizar el uso de modelos avanzados, permitiendo su ejecuci√≥n eficiente sin necesidad de hardware especializado.</p><p class="align-right"><strong>- Gracias por leer -</strong></p></div><footer class="post__inner post__footer"><p class="post__last-updated">This article was updated on febrero 18, 2026</p><div class="post__share"><h3>Share post:</h3><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fchecofran284-alt.github.io%2F2damasi%2Fcuantizacion-ia%2F" class="js-share icon brands fa-facebook" rel="nofollow noopener noreferrer"><span class="label">Facebook</span> </a><a href="https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fchecofran284-alt.github.io%2F2damasi%2Fcuantizacion-ia%2F&amp;media=undefined&amp;description=%22%20CUANTIZACI%C3%93N%20IA%20%22" class="js-share icon brands fa-pinterest" rel="nofollow noopener noreferrer"><span class="label">Pinterest</span> </a><a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fchecofran284-alt.github.io%2F2damasi%2Fcuantizacion-ia%2F" class="js-share icon brands fa-linkedin" rel="nofollow noopener noreferrer"><span class="label">LinkedIn</span></a></div><div class="post__bio"><div><h3><a href="https://checofran284-alt.github.io/2damasi/authors/francisco-ferres/" class="invert" rel="author">Francisco Ferres Brice√±o</a></h3></div></div></footer></article></div></div><div id="sidebar"><div class="inner"><nav id="menu"><header class="major"><h2>Menu</h2></header><ul><li><a href="https://checofran284-alt.github.io/2damasi/" title="principal" target="_self">üåêPrincipal</a></li><li><a href="https://checofran284-alt.github.io/2damasi/sector-automotor/" title="motor" target="_blank">üöóAutomoci√≥n</a></li><li><a href="https://checofran284-alt.github.io/2damasi/alimentacion/" title="alimentaci√≥n" target="_blank">ü•óAlimentaci√≥n</a></li><li><a href="https://checofran284-alt.github.io/2damasi/tecnologia/" title="tecno" target="_self">üíªTecnolog√≠a</a></li><li><a href="https://checofran284-alt.github.io/2damasi/mis-proyectos/" title="proyectos" target="_blank">üìΩÔ∏èMis proyectos</a></li></ul></nav><section><header class="major"><h2>Get in touch</h2></header><p><em><span style="color: #000000;">Datos de contacto</span></em></p><ul class="contact"><li class="icon solid fa-envelope"><em><a href="https://www.bing.com/ck/a?!&amp;&amp;p=ca71455edbda96520382db1137a554f7c1c5b0b30e67e159a25a03a16c3f6133JmltdHM9MTc1ODg0NDgwMA&amp;ptn=3&amp;ver=2&amp;hsh=4&amp;fclid=3c9c661a-322f-689a-21e8-700d338769b9&amp;psq=gmail&amp;u=a1aHR0cHM6Ly9tYWlsLmdvb2dsZS5jb20vbWFpbD9obD1lcw" target="_blank" rel="noopener">checofran284@gmail.com</a></em></li><li class="icon solid fa-phone"><em>(+34) 623435605</em></li><li class="icon solid fa-home"><a href="https://www.google.com/maps/place/C.+Mayor,+15,+28350+Ciempozuelos,+Madrid/@40.1585512,-3.6245033,17z/data=!3m1!4b1!4m6!3m5!1s0xd421a32fa0d1515:0x1691886e65127fe1!8m2!3d40.1585472!4d-3.6196378!16s%2Fg%2F11q2ncktdc?entry=ttu&amp;g_ep=EgoyMDI1MDkyMy4wIKXMDSoASAFQAw%3D%3D" target="_blank" rel="noopener"><em>Calle Mayor 15, 1B</em></a><br><a href="https://www.google.com/maps/place/C.+Mayor,+15,+28350+Ciempozuelos,+Madrid/@40.1585512,-3.6245033,17z/data=!3m1!4b1!4m6!3m5!1s0xd421a32fa0d1515:0x1691886e65127fe1!8m2!3d40.1585472!4d-3.6196378!16s%2Fg%2F11q2ncktdc?entry=ttu&amp;g_ep=EgoyMDI1MDkyMy4wIKXMDSoASAFQAw%3D%3D" target="_blank" rel="noopener"><em>Ciempozuelos, Madrid</em></a></li></ul></section><footer id="footer"><p class="copyright">¬© Editorial -¬† ASI II<br>Hecho por: Francisco Ferres Brice√±o</p></footer></div></div></div><script src="https://checofran284-alt.github.io/2damasi/assets/js/jquery.min.js?v=7c14a783dfeb3d238ccd3edd840d82ee"></script><script src="https://checofran284-alt.github.io/2damasi/assets/js/browser.min.js?v=c07298dd19048a8a69ad97e754dfe8d0"></script><script src="https://checofran284-alt.github.io/2damasi/assets/js/breakpoints.min.js?v=81a479eb099e3b187613943b085923b8"></script><script src="https://checofran284-alt.github.io/2damasi/assets/js/util.min.js?v=cbdaf7c20ac2883c77ae23acfbabd47e"></script><script src="https://checofran284-alt.github.io/2damasi/assets/js/main.min.js?v=08add7f6d435054ad38ec38d7cf8be40"></script><script>var images=document.querySelectorAll("img[loading]");for(var i=0;i<images.length;i++){if(images[i].complete){images[i].classList.add("is-loaded")}else{images[i].addEventListener("load",function(){this.classList.add("is-loaded")},false)}};</script></body></html>